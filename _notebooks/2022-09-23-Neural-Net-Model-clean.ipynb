{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Regression Model - Clean\"\n",
    "\n",
    "> \"Using fast.ai and Pytorch's modules, building a regression model and Neural Network using Kaggle's titanic survival data set\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- comments : False\n",
    "- author : Eric Vincent\n",
    "- categories : [fastpages, jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# uncomment and import modules\n",
    "# pip install fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()\n",
    "# from fastai.vision.all import *\n",
    "# from fastbook import *\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# to run from your workstation\n",
    "# download the titanic survival data set : train.csv\n",
    "import os\n",
    "path = os.getcwd()\n",
    "# df = pd.read_csv(f\"{path}/YOUR_FILE_LOCATION/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ericvincent/Desktop/train.csv')\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "\n",
    "def survive_loss_updated(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatDataframe :\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def splitData(self):\n",
    "        twenty_percent_df = df\n",
    "        twenty_percent_df['Male'] = twenty_percent_df['Sex']\n",
    "        twenty_percent_df['Male'] = twenty_percent_df['Male'].replace({'male': 1, 'female' : 0})\n",
    "        twenty_percent_df['Embarked_C'] = twenty_percent_df['Embarked']\n",
    "        twenty_percent_df['Embarked_C'] = twenty_percent_df['Embarked_C'].replace({'S':0, 'C':1, 'Q':0})\n",
    "        twenty_percent_df['Embarked_S'] = twenty_percent_df['Embarked']\n",
    "        twenty_percent_df['Embarked_S'] = twenty_percent_df['Embarked_S'].replace({'S':1, 'C':0, 'Q':0})\n",
    "        twenty_percent_df['Pclass1'] = twenty_percent_df['Pclass']\n",
    "        twenty_percent_df['Pclass2'] = twenty_percent_df['Pclass']\n",
    "        twenty_percent_df['Pclass1'] = twenty_percent_df['Pclass1'].replace({2:0, 3:0})\n",
    "        twenty_percent_df['Pclass2'] = twenty_percent_df['Pclass2'].replace({1:0, 3:0, 2:1})\n",
    "        twenty_percent_df = twenty_percent_df.drop(columns=['Sex', 'Age', 'Fare', 'Embarked', 'Pclass'])\n",
    "        twenty_percent_df['Embarked_S'] = twenty_percent_df['Embarked_S'].fillna(0)\n",
    "        twenty_percent_df['Embarked_C'] = twenty_percent_df['Embarked_C'].fillna(0)\n",
    "        twenty_percent_df = twenty_percent_df.drop(columns=['Name', 'Cabin', 'PassengerId', 'Ticket'])\n",
    "        eighty_percent_df = twenty_percent_df.iloc[180:]\n",
    "        twenty_percent_df = twenty_percent_df.iloc[:179]\n",
    "\n",
    "        return eighty_percent_df, twenty_percent_df\n",
    "    \n",
    "    def createTensors(self, dfName):\n",
    "        # return labels\n",
    "        survived_label_train = dfName['Survived'] == 1\n",
    "        death_label_train = dfName['Survived'] == 0\n",
    "        \n",
    "        # creating tensors\n",
    "        survived_df = dfName.loc[survived_label_train]\n",
    "        death_df = dfName.loc[death_label_train]\n",
    "\n",
    "        stacked_survived = [tensor(survived_df.iloc[num]) for num in range(len(survived_df))]\n",
    "        stacked_death = [tensor(death_df.iloc[num]) for num in range(len(death_df))]\n",
    "        \n",
    "        survive_tensors_stacked = torch.stack(stacked_survived).float()\n",
    "        death_tensors_stacked = torch.stack(stacked_death).float()\n",
    "\n",
    "        return survive_tensors_stacked, death_tensors_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "\n",
    "    model = FormatDataframe(df)\n",
    "    train, validation = model.splitData() \n",
    "    survive_tensors_stacked_train, death_tensors_stacked_train = model.createTensors(train)\n",
    "    survive_tensors_stacked_validation, death_tensors_stacked_validation = model.createTensors(validation)\n",
    "    \n",
    "    # labels on 80% of data\n",
    "    label_df = FormatDataframe(df)\n",
    "    eighty_percent_labels,_ = label_df.splitData()\n",
    "    survived_label = eighty_percent_labels['Survived'] == 1\n",
    "    death_label = eighty_percent_labels['Survived'] == 0\n",
    "    survived = eighty_percent_labels.loc[survived_label]\n",
    "    death = eighty_percent_labels.loc[death_label]\n",
    "\n",
    "\n",
    "    # create training dl\n",
    "    train_x = torch.cat([survive_tensors_stacked_train, death_tensors_stacked_train]).view(-1, 8)\n",
    "    train_y = tensor([1]*len(survive_tensors_stacked_train) + [0]*len(death_tensors_stacked_train)).unsqueeze(1)\n",
    "    dset = list(zip(train_x,train_y))\n",
    "    dl = DataLoader(dset, batch_size=8)\n",
    "    \n",
    "    # create validation dl\n",
    "    valid_x = torch.cat([survive_tensors_stacked_validation, death_tensors_stacked_validation]).view(-1, 8)\n",
    "    valid_y = tensor([1]*len(survive_tensors_stacked_validation) + [0]*len(death_tensors_stacked_validation)).unsqueeze(1)\n",
    "    valid_dset = list(zip(valid_x,valid_y))\n",
    "    valid_dl = DataLoader(valid_dset, batch_size=8)\n",
    "    \n",
    "    # finally\n",
    "    dls = DataLoaders(dl, valid_dl)\n",
    "    \n",
    "    # neural net\n",
    "    simple_net = nn.Sequential(\n",
    "        nn.Linear(8,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1,8)\n",
    "    )\n",
    "    \n",
    "    learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                    loss_func=survive_loss_updated, metrics=batch_accuracy)\n",
    "    \n",
    "    learn.fit(40, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
