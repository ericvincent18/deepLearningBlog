{
  
    
        "post0": {
            "title": "Neural Network Digit Classifier",
            "content": "Neural network image classifier using fast.ai and Pytorch modules . Install required modules and get the training and validation data from MNIST. | pip install fastbook . Collecting fastbook Downloading fastbook-0.0.28-py3-none-any.whl (719 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 719.8/719.8 kB 927.7 kB/s eta 0:00:00a 0:00:01 Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastbook) (22.1.2) Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastbook) (21.3) Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from fastbook) (2.1.0) Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from fastbook) (4.20.1) Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from fastbook) (0.8.4) Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from fastbook) (1.3.5) Requirement already satisfied: fastai&gt;=2.6 in /opt/conda/lib/python3.7/site-packages (from fastbook) (2.7.9) Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from fastbook) (0.1.97) Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fastbook) (2.28.1) Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (1.7.3) Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (3.5.3) Requirement already satisfied: spacy&lt;4 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (3.3.1) Requirement already satisfied: torch&lt;1.14,&gt;=1.7 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (1.11.0) Requirement already satisfied: fastcore&lt;1.6,&gt;=1.4.5 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (1.5.21) Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (1.0.2) Requirement already satisfied: torchvision&gt;=0.8.2 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (0.12.0) Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (6.0) Requirement already satisfied: pillow&gt;6.0.0 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (9.1.1) Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (0.0.7) Requirement already satisfied: fastprogress&gt;=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai&gt;=2.6-&gt;fastbook) (1.0.3) Requirement already satisfied: numpy&gt;=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (1.21.6) Requirement already satisfied: fsspec[http]&gt;=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (2022.7.1) Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (3.0.0) Requirement already satisfied: tqdm&gt;=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (4.64.0) Requirement already satisfied: huggingface-hub&lt;1.0.0,&gt;=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (0.8.1) Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (0.70.13) Requirement already satisfied: responses&lt;0.19 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (0.18.0) Requirement already satisfied: pyarrow&gt;=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (5.0.0) Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (3.8.1) Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (4.12.0) Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets-&gt;fastbook) (0.3.5.1) Requirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;fastbook) (2.1.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;fastbook) (2022.6.15) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;fastbook) (1.26.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.7/site-packages (from requests-&gt;fastbook) (3.3) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging-&gt;fastbook) (3.0.9) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas-&gt;fastbook) (2.8.2) Requirement already satisfied: pytz&gt;=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas-&gt;fastbook) (2022.1) Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers-&gt;fastbook) (2021.11.10) Requirement already satisfied: tokenizers!=0.11.3,&lt;0.13,&gt;=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers-&gt;fastbook) (0.12.1) Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers-&gt;fastbook) (3.7.1) Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub&lt;1.0.0,&gt;=0.1.0-&gt;datasets-&gt;fastbook) (4.3.0) Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;fastbook) (1.15.0) Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (3.1.2) Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (3.0.10) Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (59.8.0) Requirement already satisfied: typer&lt;0.5.0,&gt;=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (0.4.2) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (2.0.6) Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (1.0.3) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (1.0.8) Requirement already satisfied: thinc&lt;8.1.0,&gt;=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (8.0.17) Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (2.0.8) Requirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (1.8.2) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (0.10.1) Requirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (0.7.8) Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (2.4.4) Requirement already satisfied: pathy&gt;=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (0.6.2) Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (3.3.0) Collecting typing-extensions&gt;=3.7.4.3 Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (3.0.7) Requirement already satisfied: frozenlist&gt;=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (1.3.0) Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (4.0.2) Requirement already satisfied: aiosignal&gt;=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (1.2.0) Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (1.7.2) Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (6.0.2) Requirement already satisfied: attrs&gt;=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (21.4.0) Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp-&gt;datasets-&gt;fastbook) (0.13.0) Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata-&gt;datasets-&gt;fastbook) (3.8.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib-&gt;fastai&gt;=2.6-&gt;fastbook) (1.4.3) Requirement already satisfied: fonttools&gt;=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib-&gt;fastai&gt;=2.6-&gt;fastbook) (4.33.3) Requirement already satisfied: cycler&gt;=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib-&gt;fastai&gt;=2.6-&gt;fastbook) (0.11.0) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn-&gt;fastai&gt;=2.6-&gt;fastbook) (3.1.0) Requirement already satisfied: joblib&gt;=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn-&gt;fastai&gt;=2.6-&gt;fastbook) (1.0.1) Requirement already satisfied: smart-open&lt;6.0.0,&gt;=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy&gt;=0.3.5-&gt;spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (5.2.1) Requirement already satisfied: click&lt;9.0.0,&gt;=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer&lt;0.5.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (8.0.4) Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2-&gt;spacy&lt;4-&gt;fastai&gt;=2.6-&gt;fastbook) (2.1.1) Installing collected packages: typing-extensions, fastbook Attempting uninstall: typing-extensions Found existing installation: typing_extensions 4.3.0 Uninstalling typing_extensions-4.3.0: Successfully uninstalled typing_extensions-4.3.0 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed. tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible. tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible. tensorflow 2.6.4 requires tensorboard&lt;2.7,&gt;=2.6.0, but you have tensorboard 2.10.0 which is incompatible. tensorflow 2.6.4 requires typing-extensions&lt;3.11,&gt;=3.7, but you have typing-extensions 4.1.1 which is incompatible. tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,&lt;2.10,&gt;=1.15.5, but you have tensorflow 2.6.4 which is incompatible. tensorflow-serving-api 2.9.0 requires tensorflow&lt;3,&gt;=2.9.0, but you have tensorflow 2.6.4 which is incompatible. pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible. flax 0.6.0 requires rich~=11.1, but you have rich 12.1.0 which is incompatible. flake8 4.0.1 requires importlib-metadata&lt;4.3; python_version &lt; &#34;3.8&#34;, but you have importlib-metadata 4.12.0 which is incompatible. apache-beam 2.40.0 requires dill&lt;0.3.2,&gt;=0.3.1.1, but you have dill 0.3.5.1 which is incompatible. allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible. aiobotocore 2.3.4 requires botocore&lt;1.24.22,&gt;=1.24.21, but you have botocore 1.27.56 which is incompatible. Successfully installed fastbook-0.0.28 typing-extensions-4.1.1 WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv Note: you may need to restart the kernel to use updated packages. . . import fastbook fastbook.setup_book() . from fastai.vision.all import * from fastbook import * matplotlib.rc(&#39;image&#39;, cmap=&#39;Greys&#39;) . path = untar_data(URLs.MNIST_SAMPLE) Path.BASE_PATH = path . . 100.14% [3219456/3214948 00:01&lt;00:00] path.ls() . (#3) [Path(&#39;valid&#39;),Path(&#39;labels.csv&#39;),Path(&#39;train&#39;)] . (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/7&#39;),Path(&#39;train/3&#39;)] . threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() threes . (#6131) [Path(&#39;train/3/10.png&#39;),Path(&#39;train/3/10000.png&#39;),Path(&#39;train/3/10011.png&#39;),Path(&#39;train/3/10031.png&#39;),Path(&#39;train/3/10034.png&#39;),Path(&#39;train/3/10042.png&#39;),Path(&#39;train/3/10052.png&#39;),Path(&#39;train/3/1007.png&#39;),Path(&#39;train/3/10074.png&#39;),Path(&#39;train/3/10091.png&#39;)...] . im3_path = threes[1] im3 = Image.open(im3_path) im3 . array(im3)[4:10,4:10] . array([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=uint8) . tensor(im3)[4:10,4:10] . tensor([[ 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 29], [ 0, 0, 0, 48, 166, 224], [ 0, 93, 244, 249, 253, 187], [ 0, 107, 253, 253, 230, 48], [ 0, 3, 20, 20, 15, 0]], dtype=torch.uint8) . . im3_t = tensor(im3) df = pd.DataFrame(im3_t[:]) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . &nbsp; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 29 | 150 | 195 | 254 | 255 | 254 | 176 | 193 | 150 | 96 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 48 | 166 | 224 | 253 | 253 | 234 | 196 | 253 | 253 | 253 | 253 | 233 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 93 | 244 | 249 | 253 | 187 | 46 | 10 | 8 | 4 | 10 | 194 | 253 | 253 | 233 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 107 | 253 | 253 | 230 | 48 | 0 | 0 | 0 | 0 | 0 | 192 | 253 | 253 | 156 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 3 | 20 | 20 | 15 | 0 | 0 | 0 | 0 | 0 | 43 | 224 | 253 | 245 | 74 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 249 | 253 | 245 | 126 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 11 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 101 | 223 | 253 | 248 | 124 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 12 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 11 | 166 | 239 | 253 | 253 | 253 | 187 | 30 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 13 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 16 | 248 | 250 | 253 | 253 | 253 | 253 | 232 | 213 | 111 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 14 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 43 | 98 | 98 | 208 | 253 | 253 | 253 | 253 | 187 | 22 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 15 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 9 | 51 | 119 | 253 | 253 | 253 | 76 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 16 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 183 | 253 | 253 | 139 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 17 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 182 | 253 | 253 | 104 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 18 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 85 | 249 | 253 | 253 | 36 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 19 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 60 | 214 | 253 | 253 | 173 | 11 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 20 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 98 | 247 | 253 | 253 | 226 | 9 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 21 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 42 | 150 | 252 | 253 | 253 | 233 | 53 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 22 0 | 0 | 0 | 0 | 0 | 0 | 42 | 115 | 42 | 60 | 115 | 159 | 240 | 253 | 253 | 250 | 175 | 25 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 23 0 | 0 | 0 | 0 | 0 | 0 | 187 | 253 | 253 | 253 | 253 | 253 | 253 | 253 | 197 | 86 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 24 0 | 0 | 0 | 0 | 0 | 0 | 103 | 253 | 253 | 253 | 253 | 253 | 232 | 67 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 25 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 26 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 27 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . seven_tensors = [tensor(Image.open(o)) for o in sevens] three_tensors = [tensor(Image.open(o)) for o in threes] len(three_tensors),len(seven_tensors) . (6131, 6265) . # Check one of the images created show_image(three_tensors[1]); . . stacked_sevens = torch.stack(seven_tensors).float()/255 stacked_threes = torch.stack(three_tensors).float()/255 stacked_threes.shape . torch.Size([6131, 28, 28]) . stacked_threes.ndim . 3 . mean3 = stacked_threes.mean(0) show_image(mean3); . mean7 = stacked_sevens.mean(0) show_image(mean7); . # Check a random image and see how far its distance is from the ideal three a_3 = stacked_threes[1] show_image(a_3); . . dist_3_abs = (a_3 - mean3).abs().mean() dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt() dist_3_abs,dist_3_sqr . (tensor(0.1114), tensor(0.2021)) . dist_7_abs = (a_3 - mean7).abs().mean() dist_7_sqr = ((a_3 - mean7)**2).mean().sqrt() dist_7_abs,dist_7_sqr . (tensor(0.1586), tensor(0.3021)) . F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt() . (tensor(0.1586), tensor(0.3021)) . Compute Metrics using Broadcasting . Start by getting validation labels from the MNIST dataset for both digits . valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_3_tens.shape,valid_7_tens.shape . (torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28])) . def mnist_distance(a,b): return (a-b).abs().mean((-1,-2)) mnist_distance(a_3, mean3) . tensor(0.1114) . valid_3_dist = mnist_distance(valid_3_tens, mean3) valid_3_dist, valid_3_dist.shape . (tensor([0.1270, 0.1632, 0.1676, ..., 0.1228, 0.1210, 0.1287]), torch.Size([1010])) . def is_3(x): return mnist_distance(x,mean3) &lt; mnist_distance(x,mean7) . is_3(a_3), is_3(a_3).float() . (tensor(True), tensor(1.)) . is_3(valid_3_tens) . tensor([ True, False, False, ..., True, True, False]) . accuracy_3s = is_3(valid_3_tens).float() .mean() accuracy_7s = (1 - is_3(valid_7_tens).float()).mean() accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2 . (tensor(0.9168), tensor(0.9854), tensor(0.9511)) . Use Stochastic Gradient Descent to optimize our prediction model . Initialize the weights. | For each image, use these weights to predict whether it appears to be a 3 or a 7. | Based on these predictions, calculate how good the model is (its loss). | Calculate the gradient, which measures for each weight, how changing that weight would change the loss | Step (that is, change) all the weights based on that calculation. | Go back to the step 2, and repeat the process. | Iterate until we stop the training process | def f(x): return x**2 . xt = tensor(3.).requires_grad_() . yt = f(xt) yt . tensor(9., grad_fn=&lt;PowBackward0&gt;) . yt.backward() . xt.grad . tensor(6.) . xt = tensor([3.,4.,10.]).requires_grad_() xt # Add sum to the quadratic function so it can take a vector (rank-1 tensor) and return a scalar (rank-0 tensor) def f(x): return (x**2).sum() yt = f(xt) yt . tensor(125., grad_fn=&lt;SumBackward0&gt;) . yt.backward() xt.grad . tensor([ 6., 8., 20.]) . # w -= gradient(w) * lr . def mse(preds, targets): return ((preds-targets)**2).mean() def f(t, params): a,b,c = params return a*(t**2) + (b*t) + c . def apply_step(params, prn=True): preds = f(time, params) loss = mse(preds, speed) loss.backward() params.data -= lr * params.grad.data params.grad = None if prn: print(loss.item()) return preds . # start by by concatenating all of our images (independant x variable) into a single tensor and change them from a list of matrices (rank-3 tensor) to a list of vectors (a rank-2 tensor) -- using Pytorch&#39;s # view method. train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) . train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) train_x.shape,train_y.shape . (torch.Size([12396, 784]), torch.Size([12396, 1])) . dset = list(zip(train_x,train_y)) x,y = dset[0] x.shape,y . (torch.Size([784]), tensor([1])) . valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28) valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,1)) . bias = init_params(1) . (train_x[0]*weights.T).sum() + bias . tensor([-6.2330], grad_fn=&lt;AddBackward0&gt;) . def linear1(xb): return xb@weights + bias preds = linear1(train_x) preds . tensor([[ -6.2330], [-10.6388], [-20.8865], ..., [-15.9176], [ -1.6866], [-11.3568]], grad_fn=&lt;AddBackward0&gt;) . corrects = (preds&gt;0.0).float() == train_y corrects . tensor([[False], [False], [False], ..., [ True], [ True], [ True]]) . corrects.float().mean().item() . 0.5379961133003235 . with torch.no_grad(): weights[0] *= 1.0001 . preds = linear1(train_x) ((preds&gt;0.0).float() == train_y).float().mean().item() . 0.5379961133003235 . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . ds = L(enumerate(string.ascii_lowercase)) ds . (#26) [(0, &#39;a&#39;),(1, &#39;b&#39;),(2, &#39;c&#39;),(3, &#39;d&#39;),(4, &#39;e&#39;),(5, &#39;f&#39;),(6, &#39;g&#39;),(7, &#39;h&#39;),(8, &#39;i&#39;),(9, &#39;j&#39;)...] . # Re-initialize parameters weights = init_params((28*28,1)) bias = init_params(1) . dl = DataLoader(dset, batch_size=256) xb,yb = first(dl) xb.shape,yb.shape . (torch.Size([256, 784]), torch.Size([256, 1])) . valid_dl = DataLoader(valid_dset, batch_size=256) . batch = train_x[:4] batch.shape . torch.Size([4, 784]) . preds = linear1(batch) preds . tensor([[14.0882], [13.9915], [16.0442], [17.7304]], grad_fn=&lt;AddBackward0&gt;) . loss = mnist_loss(preds, train_y[:4]) loss . tensor(4.1723e-07, grad_fn=&lt;MeanBackward0&gt;) . loss.backward() weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 1]), tensor(-5.9512e-08), tensor([-4.1723e-07])) . def calc_grad(xb, yb, model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(-1.1902e-07), tensor([-8.3446e-07])) . calc_grad(batch, train_y[:4], linear1) weights.grad.mean(),bias.grad . (tensor(-1.7854e-07), tensor([-1.2517e-06])) . weights.grad.zero_() bias.grad.zero_(); . def train_epoch(model, lr, params): for xb,yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . (preds&gt;0.0).float() == train_y[:4] . tensor([[True], [True], [True], [True]]) . def batch_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . batch_accuracy(linear1(batch), train_y[:4]) . tensor(1.) . def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . validate_epoch(linear1) . 0.5748 . lr = 1. params = weights,bias train_epoch(linear1, lr, params) validate_epoch(linear1) . 0.7251 . for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.8569 0.9096 0.9296 0.9399 0.9467 0.9545 0.9569 0.9628 0.9647 0.9662 0.9672 0.9681 0.9725 0.9725 0.9725 0.973 0.9735 0.974 0.974 0.975 . Creating an optimizer . replace linear1 function with Pytorch&#39;s nn.lineat module reminder : nn.linear accomplishes the same thing as init_params and linear together - it contains both the weights and biases in a single class | linear_model = nn.Linear(28*28,1) . w,b = linear_model.parameters() w.shape,b.shape . (torch.Size([1, 784]), torch.Size([1])) . class BasicOptim: def __init__(self,params,lr): self.params,self.lr = list(params),lr def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr def zero_grad(self, *args, **kwargs): for p in self.params: p.grad = None . opt = BasicOptim(linear_model.parameters(), lr) . def train_epoch(model): for xb,yb in dl: calc_grad(xb, yb, model) opt.step() opt.zero_grad() . validate_epoch(linear_model) . 0.6381 . def train_model(model, epochs): for i in range(epochs): train_epoch(model) print(validate_epoch(model), end=&#39; &#39;) . train_model(linear_model, 20) . 0.4932 0.7724 0.8559 0.916 0.935 0.9472 0.9579 0.9628 0.9658 0.9677 0.9697 0.9716 0.9741 0.975 0.976 0.9765 0.9775 0.978 0.978 0.978 . # fast ai SGD class is the same as our BasicOptim class, therefore: linear_model = nn.Linear(28*28,1) opt = SGD(linear_model.parameters(), lr) train_model(linear_model, 20) . 0.4932 0.831 0.8398 0.9116 0.934 0.9477 0.956 0.9623 0.9658 0.9667 0.9697 0.9726 0.9741 0.975 0.9755 0.9765 0.9775 0.9785 0.9785 0.9785 . dls = DataLoaders(dl, valid_dl) . learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . learn.fit(10, lr=lr) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.637040 | 0.503638 | 0.495584 | 00:00 | . 1 | 0.596475 | 0.159199 | 0.878312 | 00:00 | . 2 | 0.216541 | 0.197214 | 0.819431 | 00:00 | . 3 | 0.093282 | 0.111199 | 0.908243 | 00:00 | . 4 | 0.047910 | 0.080145 | 0.931305 | 00:00 | . 5 | 0.030276 | 0.063814 | 0.946025 | 00:00 | . 6 | 0.023095 | 0.053701 | 0.955348 | 00:00 | . 7 | 0.019960 | 0.046993 | 0.961727 | 00:00 | . 8 | 0.018413 | 0.042308 | 0.965162 | 00:00 | . 9 | 0.017511 | 0.038881 | 0.967125 | 00:00 | . Adding Nonlinearity . def simple_net(xb): res = xb@w1 + b1 res = res.max(tensor(0.0)) res = res@w2 + b2 return res . w1 = init_params((28*28,30)) b1 = init_params(30) w2 = init_params((30,1)) b2 = init_params(1) . simple_net = nn.Sequential( nn.Linear(28*28,30), nn.ReLU(), nn.Linear(30,1) ) . learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy) . learn.fit(40, 0.1) . epoch train_loss valid_loss batch_accuracy time . 0 | 0.385122 | 0.388649 | 0.520118 | 00:00 | . 1 | 0.170687 | 0.256767 | 0.771835 | 00:00 | . 2 | 0.090929 | 0.123868 | 0.908734 | 00:00 | . 3 | 0.057405 | 0.081251 | 0.938665 | 00:00 | . 4 | 0.042229 | 0.062670 | 0.952895 | 00:00 | . 5 | 0.034708 | 0.052418 | 0.963690 | 00:00 | . 6 | 0.030526 | 0.046020 | 0.965653 | 00:00 | . 7 | 0.027888 | 0.041687 | 0.966634 | 00:00 | . 8 | 0.026028 | 0.038563 | 0.968106 | 00:00 | . 9 | 0.024608 | 0.036192 | 0.968597 | 00:00 | . 10 | 0.023467 | 0.034323 | 0.971050 | 00:00 | . 11 | 0.022520 | 0.032800 | 0.973013 | 00:00 | . 12 | 0.021717 | 0.031524 | 0.973503 | 00:00 | . 13 | 0.021023 | 0.030433 | 0.974975 | 00:00 | . 14 | 0.020417 | 0.029485 | 0.974975 | 00:00 | . 15 | 0.019881 | 0.028649 | 0.975466 | 00:00 | . 16 | 0.019402 | 0.027905 | 0.975957 | 00:00 | . 17 | 0.018971 | 0.027236 | 0.976938 | 00:00 | . 18 | 0.018580 | 0.026633 | 0.977429 | 00:00 | . 19 | 0.018223 | 0.026085 | 0.978410 | 00:00 | . 20 | 0.017895 | 0.025584 | 0.978410 | 00:00 | . 21 | 0.017592 | 0.025126 | 0.978901 | 00:00 | . 22 | 0.017310 | 0.024705 | 0.978901 | 00:00 | . 23 | 0.017048 | 0.024316 | 0.979882 | 00:00 | . 24 | 0.016803 | 0.023957 | 0.980373 | 00:00 | . 25 | 0.016572 | 0.023623 | 0.980373 | 00:00 | . 26 | 0.016355 | 0.023313 | 0.980864 | 00:00 | . 27 | 0.016150 | 0.023025 | 0.980864 | 00:00 | . 28 | 0.015955 | 0.022756 | 0.981354 | 00:00 | . 29 | 0.015771 | 0.022505 | 0.981354 | 00:00 | . 30 | 0.015595 | 0.022270 | 0.981354 | 00:00 | . 31 | 0.015427 | 0.022051 | 0.981845 | 00:00 | . 32 | 0.015267 | 0.021844 | 0.981845 | 00:00 | . 33 | 0.015114 | 0.021651 | 0.982826 | 00:00 | . 34 | 0.014967 | 0.021469 | 0.982826 | 00:00 | . 35 | 0.014827 | 0.021297 | 0.982826 | 00:00 | . 36 | 0.014692 | 0.021135 | 0.982826 | 00:00 | . 37 | 0.014562 | 0.020982 | 0.982826 | 00:00 | . 38 | 0.014436 | 0.020837 | 0.982826 | 00:00 | . 39 | 0.014315 | 0.020700 | 0.982826 | 00:00 | . plt.plot(L(learn.recorder.values).itemgot(2)); . learn.recorder.values[-1][2] . 0.982826292514801 . dls = ImageDataLoaders.from_folder(path) learn = vision_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy) learn.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.074170 | 0.031738 | 0.994112 | 00:23 | .",
            "url": "https://ericvincent18.github.io/fastaiMLmodel/fastpages/jupyter/2022/09/15/digit-classifier-ipynb.html",
            "relUrl": "/fastpages/jupyter/2022/09/15/digit-classifier-ipynb.html",
            "date": " • Sep 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ericvincent18.github.io/fastaiMLmodel/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ericvincent18.github.io/fastaiMLmodel/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ericvincent18.github.io/fastaiMLmodel/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ericvincent18.github.io/fastaiMLmodel/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}